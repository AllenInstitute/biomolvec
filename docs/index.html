<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rohan Gala">
<meta name="author" content="Yeganeh Marghi">
<meta name="dcterms.date" content="2025-03-02">

<title>Do DNA and Protein foundation models represent genes differently?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-81e35ebdb4125010edbabe6010586085.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>


<link rel="stylesheet" href="styles.css">
<meta name="citation_title" content="Do DNA and Protein foundation models represent genes differently?">
<meta name="citation_author" content="Rohan Gala">
<meta name="citation_author" content="Yeganeh Marghi">
<meta name="citation_publication_date" content="2025-03-02">
<meta name="citation_cover_date" content="2025-03-02">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-03-02">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Evaluating the representational power of pre-trained DNA language models for regulatory genomics;,citation_author=Ziqi Tang;,citation_author=Nirali Somia;,citation_author=Yiyang Yu;,citation_author=Peter K Koo;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_journal_title=bioRxiv;">
<meta name="citation_reference" content="citation_title=Nucleotide transformer: Building and evaluating robust foundation models for human genomics;,citation_author=Hugo Dalla-Torre;,citation_author=Liam Gonzalez;,citation_author=Javier Mendoza-Revilla;,citation_author=Nicolas Lopez Carranza;,citation_author=Adam Henryk Grzywaczewski;,citation_author=Francesco Oteri;,citation_author=Christian Dallago;,citation_author=Evan Trop;,citation_author=Bernardo P Almeida;,citation_author=Hassan Sirelkhatim;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_journal_title=Nature Methods;,citation_publisher=Nature Publishing Group US New York;">
<meta name="citation_reference" content="citation_title=Simulating 500 million years of evolution with a language model;,citation_author=Thomas Hayes;,citation_author=Roshan Rao;,citation_author=Halil Akin;,citation_author=Nicholas J Sofroniew;,citation_author=Deniz Oktay;,citation_author=Zeming Lin;,citation_author=Robert Verkuil;,citation_author=Vincent Q Tran;,citation_author=Jonathan Deaton;,citation_author=Marius Wiggert;,citation_author=others;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_journal_title=Science;,citation_publisher=American Association for the Advancement of Science;">
<meta name="citation_reference" content="citation_title=Efficient querying of genomic reference databases with gget;,citation_author=Laura Luebbert;,citation_author=Lior Pachter;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=1;,citation_volume=39;,citation_journal_title=Bioinformatics;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=Joint inference of discrete cell types and continuous type-specific variability in single-cell datasets with MMIDAS;,citation_author=Yeganeh Marghi;,citation_author=Rohan Gala;,citation_author=Fahimeh Baftizadeh;,citation_author=Uygar Sümbül;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=9;,citation_volume=4;,citation_journal_title=Nature Computational Science;,citation_publisher=Nature Publishing Group US New York;">
<meta name="citation_reference" content="citation_title=Structure-based protein clustering sometimes, but not always, provides insight into protein function;,citation_author=Brae M. Bigge;,citation_author=Ryan York;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_journal_title=Arcadia Science;,citation_publisher=Arcadia Science;">
<meta name="citation_reference" content="citation_title=Gene set knowledge discovery with enrichr;,citation_author=Z. Xie;,citation_author=A. Bailey;,citation_author=M. V. Kuleshov;,citation_author=D. J. Clarke;,citation_author=J. E. Evangelista;,citation_author=S. L. Jenkins;,citation_author=A. Lachmann;,citation_author=M. L. Wojciechowicz;,citation_author=E. Kropiwnicki;,citation_author=K. M. Jagodnik;,citation_author=M. Jeon;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_journal_title=Current Protocols;">
<meta name="citation_reference" content="citation_title=Protocol update for large-scale genome and gene function analysis with the PANTHER classification system (v. 14.0);,citation_author=H. Mi;,citation_author=A. Muruganujan;,citation_author=X. Huang;,citation_author=D. Ebert;,citation_author=C. Mills;,citation_author=X. Guo;,citation_author=P. D. Thomas;,citation_publication_date=2019-03;,citation_cover_date=2019-03;,citation_year=2019;,citation_issue=3;,citation_volume=14;,citation_journal_title=Nature protocols;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=A coupled autoencoder approach for multi-modal analysis of cell types;,citation_author=R. Gala;,citation_author=N. Gouwens;,citation_author=Z. Yao;,citation_author=A. Budzillo;,citation_author=O. Penn;,citation_author=B. Tasic;,citation_author=G. Murphy;,citation_author=H. Zeng;,citation_author=U. Sümbül;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=32;,citation_conference_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Learning transferable visual models from natural language supervision;,citation_author=Alec Radford;,citation_author=Jong Wook Kim;,citation_author=Chris Hallacy;,citation_author=Aditya Ramesh;,citation_author=Gabriel Goh;,citation_author=Sandhini Agarwal;,citation_author=Girish Sastry;,citation_author=Amanda Askell;,citation_author=Pamela Mishkin;,citation_author=Jack Clark;,citation_author=Gretchen Krueger;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=139;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Sequence modeling and design from molecular to genome scale with evo;,citation_author=Eric Nguyen;,citation_author=Michael Poli;,citation_author=Matthew G. Durrant;,citation_author=Brian Kang;,citation_author=Dhruva Katrekar;,citation_author=David B. Li;,citation_author=Liam J. Bartie;,citation_author=Armin W. Thomas;,citation_author=Samuel H. King;,citation_author=Garyk Brixi;,citation_author=Jeremy Sullivan;,citation_author=Madelena Y. Ng;,citation_author=Ashley Lewis;,citation_author=Aaron Lou;,citation_author=Stefano Ermon;,citation_author=Stephen A. Baccus;,citation_author=Tina Hernandez-Boussard;,citation_author=Christopher Ré;,citation_author=Patrick D. Hsu;,citation_author=Brian L. Hie;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://www.science.org/doi/10.1126/science.ado9336;,citation_issue=6723;,citation_doi=10.1126/science.ado9336;,citation_volume=386;,citation_journal_title=Science;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Do DNA and Protein foundation models represent genes differently?</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Rohan Gala </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Allen Institute for Brain Science
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Yeganeh Marghi </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Allen Institute for Brain Science
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">March 2, 2025</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      </div>
    </div>



    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a></li>
  <li><a href="#carbon-footprint" id="toc-carbon-footprint" class="nav-link" data-scroll-target="#carbon-footprint">Carbon footprint</a></li>
  <li><a href="#code" id="toc-code" class="nav-link" data-scroll-target="#code">Code</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Genomic foundation models (FM) have adopted different perspectives to represent nucleotide sequences. Protein FMs relate nucleotide sequence to protein structure, whereas DNA FMs relate it to RNA expression level, chromatin accessibility, and other epigenetic features. The former perspective captures structural/functional properties, whereas the latter captures molecular grammar and regulatory logic. For the hackathon, we obtained and evaluated joint-clusters of nucleotide sequence representations obtained by FMs that adopt these distinct perspectives.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>We started with 20,909 mouse and 19,364 human for which cDNA sequences were available in the Ensembl database. The amino acid sequences for these genes were obtained using the <code>gget</code> package <span class="citation" data-cites="luebbert2023efficient">(<a href="#ref-luebbert2023efficient" role="doc-biblioref">Luebbert and Pachter 2023</a>)</span>.</p>
<p>Embeddings for the nucleotide and amino acid sequences for each gene were obtained with the Nucleotide Transformer <span class="citation" data-cites="dalla2024nucleotide">(<a href="#ref-dalla2024nucleotide" role="doc-biblioref">Dalla-Torre et al. 2024</a>)</span> and ESM3 <span class="citation" data-cites="hayes2025simulating">(<a href="#ref-hayes2025simulating" role="doc-biblioref">Hayes et al. 2025</a>)</span> respectively. We refer to these as NT- and ESM3-embeddings. A 2d UMAP projection of these embeddings is shown in <a href="#fig-mouse-umap" class="quarto-xref">Figure&nbsp;1</a>. We used the Leiden algorithm to cluster the NT- and ESM3-embeddings individually, without any dimensionality reduction. This defines the 20 <code>leiden-nt</code> labels, and 55 <code>leiden-esm3</code> labels. This exercise suggested that the NT-embeddings have much less structure than the ESM3 embeddings.</p>
<div id="fig-mouse-umap" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mouse-umap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<iframe width="700" height="350" src="./umap_plot.html">
</iframe>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mouse-umap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: 2d UMAP projection of the NT- and ESM3-embeddings for mouse genes. Colors can be chosen based on Leiden clustering individually performed on NT- and ESM3-embeddings, or MMIDAS consensus clusters obtained jointly. Hover on the dots to see the gene symbols and their cluster memberships.
</figcaption>
</figure>
</div>
<p>We also included the 27 <code>mmidas-joint</code> labels in <a href="#fig-mouse-umap" class="quarto-xref">Figure&nbsp;1</a> obtained with MMIDAS <span class="citation" data-cites="marghi2024joint">(<a href="#ref-marghi2024joint" role="doc-biblioref">Marghi et al. 2024</a>)</span>. The consensus score is a way to determine if a given gene can be assigned to the same cluster, irrespective of whether we use the NT- or ESM3-embeddings. The overall consensus score (over all genes) as a function of the number of joint clusters in the iterative MMIDAS training process is shown in <a href="#fig-mmidas-consensus" class="quarto-xref">Figure&nbsp;2</a> (left).</p>
<div id="fig-mmidas-consensus" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mmidas-consensus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./mmidas_consensus.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;2: MMIDAS for consensus clusters Left: The consensus score across different views (NT- and ESM3-embeddings) of genes as a function of dimensionality of the discrete representation layer in MMIDAS. Black dashed line indicates the maximum number of categories with consensus score of 0.9. Right: MMIDAS-assigned clusters are highly coherent across the two views (dominant diagonal in the heatmap)."><img src="./mmidas_consensus.png" class="img-fluid figure-img" width="650"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mmidas-consensus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <strong>MMIDAS for consensus clusters</strong> Left: The consensus score across different views (NT- and ESM3-embeddings) of genes as a function of dimensionality of the discrete representation layer in MMIDAS. Black dashed line indicates the maximum number of categories with consensus score of 0.9. Right: MMIDAS-assigned clusters are highly coherent across the two views (dominant diagonal in the heatmap).
</figcaption>
</figure>
</div>
<p>We investigated genes included in MMIDAS joint clusters with <code>gget</code><span class="citation" data-cites="luebbert2023efficient">(<a href="#ref-luebbert2023efficient" role="doc-biblioref">Luebbert and Pachter 2023</a>)</span>. In particular, <code>gget</code> provides an interface to <a href="https://maayanlab.cloud/Enrichr/">Enrichr</a> <span class="citation" data-cites="xie2021gene">(<a href="#ref-xie2021gene" role="doc-biblioref">Xie et al. 2021</a>)</span>, and results are based on the <code>GO Biological Process</code> category with annotations from the 2021 annotation release.</p>
<div id="fig-go-enrichment" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-go-enrichment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./go_enrichment.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;3: MMIDAS joint clusters capture functionally relevant genes GO enrichment of genes in the MMIDAS joint clusters. The position of genes in the NT- and ESM3-embedding UMAPs are shown in the right panels. The top two panels are based on GO ontology 2021, and the bottom-most panel is based on GO ontology 2024. Full results for the bottom panel are available here."><img src="./go_enrichment.png" class="img-fluid figure-img" width="750"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-go-enrichment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>MMIDAS joint clusters capture functionally relevant genes</strong> GO enrichment of genes in the MMIDAS joint clusters. The position of genes in the NT- and ESM3-embedding UMAPs are shown in the right panels. The top two panels are based on GO ontology 2021, and the bottom-most panel is based on GO ontology 2024. Full results for the bottom panel are available <a href="https://github.com/AllenInstitute/biomolvec-data/blob/main/mmidas-joint-18-analysis.txt">here</a>.
</figcaption>
</figure>
</div>
<p>Among the clusters we investigated, we noticed that none of the 215 genes in <code>mmidas-joint-18</code> were found through <code>gget</code>. The gene names suggested that these genes are all part of the immunoglobin family. These genes also appear in clustered on both the NT- and ESM3-embedding UMAPs. Moreover, we noticed that <a href="https://github.com/AllenInstitute/biomolvec-data/blob/main/mmidas-joint-18-genes.txt">immunoglobin genes</a> also cluster together in a single <code>mmidas-joint</code> grouping of human genes. We used the PANTHER Overrepresentation Test <span class="citation" data-cites="mi2019protocol">(<a href="#ref-mi2019protocol" role="doc-biblioref">Mi et al. 2019</a>)</span> through the <a href="https://www.geneontology.org/">GO ontology resource</a> which uses a more recent version of the GO ontology to investigate this further. This analysis found that genes in this cluster are significantly overrepresented for <a href="https://amigo.geneontology.org/amigo/term/GO:0016064">immunoglobulin mediated immune response</a> and <a href="https://amigo.geneontology.org/amigo/term/GO:0003823">antigen binding</a>, among several other terms.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>Our analysis suggests that genes that are grouped in one view are not as coherent in another view, see different label sets in <a href="#fig-mouse-umap" class="quarto-xref">Figure&nbsp;1</a> and particular examples in <a href="#fig-go-enrichment" class="quarto-xref">Figure&nbsp;3</a>. As with much of biology, some gene relationships are shared, while others are distinct. Nevertheless, the joint clusters we obtain with post-hoc alignment are meaningful. Our analysis captured a set of immunoglobin genes across species that are annotated only in more recent versions of commonly used databases for gene annotation. This approach may therefore offer a way to refine ontologies.</p>
<p>A subset of inputs that distinct foundation models are trained on are biologically coherent entities, e.g.&nbsp;genes. Our preliminary analysis already captures some relationships across two such models - one trained only on DNA sequences to predict masked tokens, and another trained only on amino acid sequences to predict protein structure. Curating and leveraging such data through analyses of multiple existing foundation models could be used to align representations in new models with various coupling strategies <span class="citation" data-cites="gala2019coupled marghi2024joint radford2021learning">(<a href="#ref-gala2019coupled" role="doc-biblioref">Gala et al. 2019</a>; <a href="#ref-marghi2024joint" role="doc-biblioref">Marghi et al. 2024</a>; <a href="#ref-radford2021learning" role="doc-biblioref">Radford et al. 2021</a>)</span> - towards building truly multimodal biological foundation models.</p>
<p>One hurdle towards this vision is that large transformer-like models assign different meaning and utility to representations extracted from different layers, and for particular input tokens depending on the training objective. Choosing a single representation per input sequence <em>post-hoc</em>, and without a well-defined task can be tricky. Here we followed examples in the respective repositories for the models we used to obtain a single representation for each gene, which may not be the best approach.</p>
<p>The downstream analysis with various bioinformatics tools for overrepresentation should be interpreted with caution. We used them here as an exploratory tool to interpret our groupings.</p>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>We obtained genome-wide cDNA sequences for human and mouse from <a href="https://useast.ensembl.org/index.html">Ensembl</a>. Custom scripts and the <code>gget</code> package <span class="citation" data-cites="luebbert2023efficient">(<a href="#ref-luebbert2023efficient" role="doc-biblioref">Luebbert and Pachter 2023</a>)</span> were used to obtain the nucleotide and amino acid sequences corresponding to all available mouse and human genes in the Ensembl database. We ended up with 20,909 mouse and 19,364 human genes at this stage.</p>
<div id="tbl-aa-emb" class="rpe striped hover borderless responsive-sm table-caption quarto-float quarto-figure quarto-figure-center anchored" style="font-size: 95%; width: 90%; margin: auto auto;">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-aa-emb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: <strong>Summary of amino acid sequence embeddings</strong> The safety filter exceptions ultimately influence a small fraction of the sequences, so we retained them all for the downstream analysis.
</figcaption>
<div aria-describedby="tbl-aa-emb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="table-responsive-sm">
<table class="rpe table-striped table-hover table-borderless table-caption caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Species</th>
<th style="text-align: center;">Initial set</th>
<th style="text-align: center;">Safety filter exceptions</th>
<th style="text-align: center;">Enabled by workaround</th>
<th style="text-align: center;">Embeddings available</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Mouse</td>
<td style="text-align: center;">20,909</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">546</td>
<td style="text-align: center;">20,877</td>
</tr>
<tr class="even">
<td style="text-align: center;">Human</td>
<td style="text-align: center;">19,364</td>
<td style="text-align: center;">26</td>
<td style="text-align: center;">596</td>
<td style="text-align: center;">19,338</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
<p>ESM3 has safety checks that prevent it from embedding certain amino acid sequences. We could bypass these filters by masking a variable fraction of amino acids in the sequence. Even with this approach, embeddings for a small fraction of amino acid sequences could not be obtained, <a href="#tbl-aa-emb" class="quarto-xref">Table&nbsp;1</a>.</p>
<div id="fig-seq-length" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-seq-length-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./length_dist.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Sequence length distribution"><img src="./length_dist.png" class="img-fluid figure-img" width="650"></a></p>
<figcaption>Sequence length distribution</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seq-length-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>Sequence length distribution</strong> Distribution of nucleotide and amino acid sequences corresponding to all genes in the Ensembl database for mouse and human. Black line indicates the sequence length corresponding to the maximum token length for the nucleotide transformer. The x-axis is truncated, and excludes a small number of sequences (e.g.&nbsp;Ttn, which has a sequence length of 1,23,179 nucleotides and 35,390 amino-acids)
</figcaption>
</figure>
</div>
</section>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<p>Nucleotide Transformer <span class="citation" data-cites="dalla2024nucleotide">(<a href="#ref-dalla2024nucleotide" role="doc-biblioref">Dalla-Torre et al. 2024</a>)</span> as our DNA FM and ESM3 <span class="citation" data-cites="hayes2025simulating">(<a href="#ref-hayes2025simulating" role="doc-biblioref">Hayes et al. 2025</a>)</span> as our protein FM. Finally, we used MMIDAS <span class="citation" data-cites="marghi2024joint">(<a href="#ref-marghi2024joint" role="doc-biblioref">Marghi et al. 2024</a>)</span> to obtain joint embeddings of genes based on their representations in the DNA and protein FMs.</p>
<p><strong>Nucleotide Transformer:</strong> This model <span class="citation" data-cites="dalla2024nucleotide">(<a href="#ref-dalla2024nucleotide" role="doc-biblioref">Dalla-Torre et al. 2024</a>)</span> is pre-trained to predict masked tokens in DNA sequences. Tokens in the nucleotide transformer are used to represent k-mers (k=6). Adding a few extra tokens to indicate <code>CLS</code>, <code>MASK</code>, <code>PAD</code> etc. takes the vocabulary size to 4,104. The maximum token length in the models considered is 1,000, which corresponds to sequences with length of roughly 5,952 nucleotides. We truncated any input sequence to match this maximum value, <a href="#fig-seq-length" class="quarto-xref">Figure&nbsp;4</a>.</p>
<p>We obtained embeddings corresonding to the <code>CLS</code> token for all genes. There is no single representation for which layer to extract such embeddings from. We followed examples in the repository, and obtained representations from layer 20 of the <code>500M multi v2</code> and <code>500M human</code> models for the mouse and human nucleotide sequences respectively. The dimension of the embeddings are of 1,280 for mouse genes, and 1024 for human genes. We refer to these as NT embeddings.</p>
<p><strong>ESM3:</strong> ESM3-open<span class="citation" data-cites="hayes2025simulating">(<a href="#ref-hayes2025simulating" role="doc-biblioref">Hayes et al. 2025</a>)</span> is a 98B parameter model that is trained on 2.78B natural protein sequences to predict sequence, structure, and functional aspects using a masked language modeling objective. This model incorporates a guardrails that can prevent inference on potentially hazardous sequences, see <a href="https://huggingface.co/EvolutionaryScale/esm3-sm-open-v1">model card</a>.</p>
<p>The model exposes per-residue embeddings, which represent each amino acid within the sequence, and a mean embedding, which is the average of all residue embeddings across the entire protein sequence. For both mouse and human sequences, we only use the 1,536 dimensional mean embedding to represent the amino acid sequences corresponding to the genes. We refer to these as ESM3 embeddings.</p>
<p><strong>MMIDAS:</strong> <span class="citation" data-cites="marghi2024joint">(<a href="#ref-marghi2024joint" role="doc-biblioref">Marghi et al. 2024</a>)</span> recently proposed a model to obtain joint embeddings of multimodal single-cell resolution data. Treating genes as our samples, and NT- and ESM3-embeddings as ‘modalities’, we obtained consensus clusters for genes.</p>
<p>MMIDAS sparsifies the discrete representation layer to identify an optimal number of consensus categories across modalities. At the start of training, the network initializes an overparameterized discrete latent space, establishing an upper bound on the number of clusters. The model refines the dimensionality of the discrete latent space (equivalent to number of categories or clusters) by evaluating each category’s contribution based on a consensus measure between the modalities. Categories that do not maintain similar probabilities across modalities are pruned. This iterative process continues until all remaining categories satisfy a predefined minimum consensus threshold.</p>
</section>
<section id="carbon-footprint" class="level2">
<h2 class="anchored" data-anchor-id="carbon-footprint">Carbon footprint</h2>
<p>In relation to the sustainability focus of the hackathon, we calculated a rough estimate of the carbon footprint of the computations we performed.</p>
<p><strong>Nucleotide Transformer:</strong> A single <code>A100</code> GPU on the local high performance computing cluster was used to run inference with nucleotide transformer. The largest batch size we could use without running out of memory on this hardware was 20, and the inference time for the dataset was around 20 minutes. The total energy consumption for this exercise is estimated to be 0.2 kW.</p>
<p><strong>ESM3:</strong> We ran computations on <code>ml.g5.2xlarge</code> instances via Amazon SageMaker using an endpoint for the ESM3 hosted on their marketplace. Generating embeddings for all genes of a single species took about 10 hours. The total energy consumption for <code>ml.g5.2xlarge</code> was about 6.0 kW.</p>
<p><strong>MMIDAS:</strong> For training MMIDAS, we utilized the local high-performance computing (HPC), using one <code>Tesla V100 SXM2</code> GPU with a 0.3 kW power rating. Training runs took 23 hours each (for mouse and human), resulting in a total energy consumption of 14.0 kW.</p>
<p><strong>Evo2:</strong> We attempted to install and use a more recent DNA foundation model, Evo2 <span class="citation" data-cites="nguyen2024sequence">(<a href="#ref-nguyen2024sequence" role="doc-biblioref">Nguyen et al. 2024</a>)</span>. The <a href="https://docs.nvidia.com/nim/bionemo/evo2/1.0.0/prerequisites.html">minimum requirements</a> to use this model requires <code>H100</code> or <code>H200</code> GPUs. We used 2 hours of an <code>ml.p5.48xlarge</code> instance for this. Using the 700W maximum power rating for 8 x <code>H100</code> on this instance leads to an estimate of 11.2 kW.</p>
<p>All embeddings were saved on shared storage to prevent duplicate computations by team members. Future experiments could incorporate tools like <a href="https://mlco2.github.io/codecarbon/index.html">CodeCarbon</a> to more reliably track the carbon footprint of experiments run across computing environments and devices.</p>
</section>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<p>See the <a href="https://github.com/alleninstitute/biomolvec-data/">biomolvec</a> and <a href="https://github.com/alleninstitute/nautilex-esm/">nautilex-esm</a> repositories for related notebooks and scripts.</p>

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-dalla2024nucleotide" class="csl-entry" role="listitem">
Dalla-Torre, Hugo, Liam Gonzalez, Javier Mendoza-Revilla, Nicolas Lopez Carranza, Adam Henryk Grzywaczewski, Francesco Oteri, Christian Dallago, et al. 2024. <span>“Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics.”</span> <em>Nature Methods</em>, 1–11.
</div>
<div id="ref-gala2019coupled" class="csl-entry" role="listitem">
Gala, R., N. Gouwens, Z. Yao, A. Budzillo, O. Penn, B. Tasic, G. Murphy, H. Zeng, and U. Sümbül. 2019. <span>“A Coupled Autoencoder Approach for Multi-Modal Analysis of Cell Types.”</span> In <em>Advances in Neural Information Processing Systems</em>. Vol. 32.
</div>
<div id="ref-hayes2025simulating" class="csl-entry" role="listitem">
Hayes, Thomas, Roshan Rao, Halil Akin, Nicholas J Sofroniew, Deniz Oktay, Zeming Lin, Robert Verkuil, et al. 2025. <span>“Simulating 500 Million Years of Evolution with a Language Model.”</span> <em>Science</em>, eads0018.
</div>
<div id="ref-luebbert2023efficient" class="csl-entry" role="listitem">
Luebbert, Laura, and Lior Pachter. 2023. <span>“Efficient Querying of Genomic Reference Databases with Gget.”</span> <em>Bioinformatics</em> 39 (1): btac836.
</div>
<div id="ref-marghi2024joint" class="csl-entry" role="listitem">
Marghi, Yeganeh, Rohan Gala, Fahimeh Baftizadeh, and Uygar Sümbül. 2024. <span>“Joint Inference of Discrete Cell Types and Continuous Type-Specific Variability in Single-Cell Datasets with MMIDAS.”</span> <em>Nature Computational Science</em> 4 (9): 706–22.
</div>
<div id="ref-mi2019protocol" class="csl-entry" role="listitem">
Mi, H., A. Muruganujan, X. Huang, D. Ebert, C. Mills, X. Guo, and P. D. Thomas. 2019. <span>“Protocol Update for Large-Scale Genome and Gene Function Analysis with the PANTHER Classification System (v. 14.0).”</span> <em>Nature Protocols</em> 14 (3): 703–21.
</div>
<div id="ref-nguyen2024sequence" class="csl-entry" role="listitem">
Nguyen, Eric, Michael Poli, Matthew G. Durrant, Brian Kang, Dhruva Katrekar, David B. Li, Liam J. Bartie, et al. 2024. <span>“Sequence Modeling and Design from Molecular to Genome Scale with Evo.”</span> <em>Science</em> 386 (6723): eado9336. <a href="https://doi.org/10.1126/science.ado9336">https://doi.org/10.1126/science.ado9336</a>.
</div>
<div id="ref-radford2021learning" class="csl-entry" role="listitem">
Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. <span>“Learning Transferable Visual Models from Natural Language Supervision.”</span> In <em>International Conference on Machine Learning</em>, 139:8748–63. Proceedings of Machine Learning Research. PMLR.
</div>
<div id="ref-xie2021gene" class="csl-entry" role="listitem">
Xie, Z., A. Bailey, M. V. Kuleshov, D. J. Clarke, J. E. Evangelista, S. L. Jenkins, A. Lachmann, et al. 2021. <span>“Gene Set Knowledge Discovery with Enrichr.”</span> <em>Current Protocols</em>, March.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>